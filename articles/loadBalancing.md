## 2.0 介绍
今天良好的互联网用户体验需要良好的性能和高可用的服务。 为此，运行同一系统的多个副本，并在其上分配负载。 随着负载的增加，系统的另一个副本可以接入处理任务。 这种架构技术称为水平扩展。 基于软件的基础设施因其灵活性而日益普及，开辟了广阔的可能性。 对于只有两个实例或者在全球有数千个实例的系统，需要一个与基础架构一样动态的负载平衡解决方案。 NGINX以多种方式满足了这一需求，例如HTTP，TCP和UDP负载平衡，我们将在本章中介绍。

在平衡负载时，重要的是对客户产生好的影响。许多现代Web体系结构使用无状态应用程序层，将状态存储在共享内存或数据库中。然而，并不是所有的情况都这样。会话状态在交互式应用程序中非常有价值且非常庞大。出于多种原因，此状态可能存储在应用程序服务器的本地;例如，在应用程序中，所处理的数据太大，以致网络开销在性能上产生了比较大的影响。当状态存储在本地应用程序服务器上时，对于用户体验来说，后续请求继续传递到同一服务器是非常重要的。这种情况的另一个方面是在会话结束之前不应该释放服务器。大规模处理有状态的应用程序需要智能负载平衡器。 NGINX Plus通过跟踪cookie或路由提供多种方法来解决此问题。本章介绍会话持久性，因为它与NGINX和NGINX Plus的负载平衡有关。

确保NGINX服务良好运行也很重要。有多种原因导致会应用不能访问，可能是因为网络连接，服务器故障或应用程序故障。因此，代理和负载均衡器必须足够智能，以检测上游服务器的故障并停止向它们传递流量;否则，客户端将一直等待导致超时。服务器发生故障时缓解服务质量下降的一种方法是让代理检查上游服务器的运行状况。 NGINX提供两种不同类型的健康检查：被动检查，可用于开源版本;主动检查，仅在NGINX Plus中可用。定期进行的主动运行状况检查将与上游服务器建立连接或请求，并可以验证响应是否正确。当客户端发出请求或连接时，被动运行状况检查会监视上游服务器的连接或响应。您可能希望使用被动运行状况检查来减少上游服务器的负载，并且您可能希望在客户端发生故障之前使用主动运行状况检查来确定上游服务器的故障。本章的尾部将介绍检查监视负载均衡的上游应用程序服务器的运行状况。

## 2.1 HTTP负载均衡
### 需求
您需要在两个或更多的HTTP服务器之间分配负载。

### 解决方案
使用NGINX的HTTP负载均衡需要使用upstream模块
```
upstream backend {
	server 10.10.12.45:80      weight=1;
	server app.example.com:80  weight=2;
}
server {
	location / {
		proxy_pass http://backend;
	} 
}
```
此配置在两个HTTP服务器的80端口上进行分配负载。weight参数表示权重，weight参数默认为1。

### 详解
HTTP upstream 模块控制HTTP的负载均衡。 此模块通过Unix套接字、IP地址、DNS记录的任意组合定义目标池。 upstream模块还定义了如何将单个请求分配给upstream服务器。
每个upstream目标都是由server指令在upstream池中定义的。 server指令提供了Unix套接字，IP地址或FQDN，以及许多可选参数。 可选参数可以更好地控制请求的路由。 这些参数包括平衡算法中服务器的权重; 服务器是处于待机模式，可用还是不可用; 以及如何确定服务器是否不可用.NGINX Plus提供了许多其他方便的参数，例如服务器的连接限制，高级DNS解析控制，以及在启动后缓慢增加与服务器的连接的能力。

## 2.2 TCP负载均衡
### 需求
您需要在两个或更多TCP服务器之间分配负载。

### 解决方案
使用NGINX的stream模块在upstream块上进行TCP服务器的负载均衡：
```
stream {
	upstream mysql_read {
		server read1.example.com:3306  weight=5;
		server read2.example.com:3306;
		server 10.10.12.34:3306		backup;
	}
	server {
		listen 3306;
       		proxy_pass mysql_read;
 	}
}
```

此示例中的server块指示NGINX侦听TCP的3306端口，并平衡两个MySQL数据库读取副本之间的负载，并列出另一个作为备份（如果初选的服务器异常，则将替补）。此配置不会添加到conf.d文件夹中，因为该文件夹包含在http块中; 相反，您应该创建另一个名为stream.conf.d的文件夹，在nginx.conf文件中打开stream块，并包含用于stream配置的新文件夹。

### 详解
TCP负载平衡由NGINX stream模块定义。与HTTP模块一样，stream模块允许您定义服务器的upstream池并配置监听服务器。配置服务器以侦听指定端口时，必须定义要侦听的端口，或者可选的定义地址和端口。

TCP负载平衡的upstream非常类似于HTTP的upstream，因为它将upstream资源定义为服务器，配置了Unix socket，IP或完全限定域名（FQDN），以及服务器权重，最大连接数，DNS解析器和连接加速期;还有可以设定服务器处于活动，关闭或备份模式。

NGINX Plus为TCP负载平衡提供了更多功能。 NGINX Plus中提供的这些高级功能可以在本书中找到。所有负载平衡的运行状况检查将在本章后面介绍。

## 2.3 UDP负载均衡
### 需求
您需要在两个或更多UDP服务器之间分配负载。

### 解决方案
使用NGINX的stream模块在upstream块上进行UDP服务器的负载均衡：
将upstream块定义为udp:
```
 stream {
        upstream ntp {
            server ntp1.example.com:123  weight=2;
            server ntp2.example.com:123;
        }
        server {
            listen 123 udp;
            proxy_pass ntp;
        }
}
```
此部分配置使用UDP协议平衡两个时间协议（NTP）服务器之间的负载。 指定UDP负载均衡非常简单，只需在listen指令上使用udp参数。

如果你的负载均衡服务需要在客户端和服务器之间来回发送的多个数据包，您可以指定reuseport参数。 比如OpenVPN，因特网协议语音（VoIP），虚拟桌面解决方案和数据报传输层安全（DTLS）。 以下是使用NGINX处理OpenVPN连接并将其代理到本地运行的OpenVPN服务的示例：

```
 stream {
        server {
            listen 1195 udp reuseport;
            proxy_pass 127.0.0.1:1194;
        }
}
```

### 详解
您可能会问：“当我在DNS A或SRV记录中有多个主机时，为什么需要负载均衡器？”答案是，我们不仅可以用其他的负载均衡算法来均衡负载，而且我们可以负载均衡DNS服务器本身。 UDP服务构成了我们在网络系统中依赖的许多服务，例如DNS，NTP和VoIP。 UDP负载均衡可能不太常见，但在规模世界中同样有用。

您可以在stream模块中找到UDP负载平衡，就像TCP一样，并且以相似的方式配置它。 主要区别在于listen指令指定open socket用于处理数据报。 使用数据报时，还有一些其他指令可能适用于TCP中不存在的指令，例如proxy_response指令，它指定NGINX可以从上游服务器发送多少预期响应。 默认情况下，这是无限制的，直到达到proxy_timeout限制。

reuseport参数指示NGINX为每个工作进程创建一个单独的侦听套接字。 这允许内核消除工作进程之间的传入连接，以处理在客户端和服务器之间发送的多个数据包。 重用端口功能仅适用于Linux内核3.9及更高版本，DragonFly BSD和FreeBSD 12及更高版本。

## 2.4 负载均衡的实现方法
### 需求
循环负载平衡不适合您的情况，因为您有异构工作负载或服务器池。

### 解决方案
使用一种NGINX的负载均衡方法，例如最少连接，最少时间，通用哈希，IP哈希或随机：

```
upstream backend {
        least_conn;
        server backend.example.com;
        server backend1.example.com;
}
```

此示例将后端upstream池的负载均衡算法设置为最少连接。 所有负载均衡算法（通用哈希，随机和最小时间除外）都是独立的指令，例如前面的示例。 下文解释了这些指令的参数。

### 详解
并非所有请求或数据包都具有相同的权重，鉴于此，循环法，甚至前面示例中使用的加权循环法，不适合所有应用程序或流量的需要。 NGINX提供了许多负载均衡算法，您可以使用它们来适应特定的用例。 除了能够选择这些负载均衡算法或方法之外，您还可以配置它们。 以下负载平衡均法可用于上游HTTP，TCP和UDP池。

*循环法*

这是默认的负载均衡方法，它按照上游池中服务器列表的顺序分配请求。 如果上游服务器的容量不同，您还可以考虑使用加权循环。 权重的整数值越高，服务器在循环中的优势就越大。 权重背后的算法只是权重平均值的统计概率。

*最少连接*

此方法通过将当前请求分发到最少连接数的上游服务器来平衡负载。 在决定向哪个服务器发送连接时，最小连接跟循环一样，也可以考虑加入权重。 指令名称为least_conn。

*最少时间*

仅在NGINX Plus中可用。此方法是最复杂的负载平衡算法之一，可满足高性能Web应用程序的需求。 此算法是一个值加上最小连接，因为少量连接并不一定意味着最快的响应。 必须为此指令指定header或last_byte的参数。 指定标头时，使用接收响应标头的时间。 指定last_byte时，将使用接收完整响应的时间。 指令名称为least_time。

*通用哈希*

管理员使用给定文本，请求或运行时的变量来定义散列。 NGINX通过为当前请求生成哈希并将其放在上游服务器上来在服务器之间分配负载。 当您需要更多地控制发送请求的位置或确定哪个上游服务器最有可能缓存数据时，此方法非常有用。 请注意，在池中添加或删除服务器时，将重新分配散列请求。 该算法具有一致的可选参数，以最小化重新分配的影响。 指令名称是hash。

*随机*

此方法用于指示NGINX从组中随机选择服务器，并考虑服务器权重。 可选的两个[method]参数指示NGINX随机选择两个服务器，然后使用提供的负载平衡方法在这两个服务器之间进行平衡。 默认情况下，如果在没有方法的情况下传递了两个，则使用least_conn方法。 随机负载均衡的指令名称为random。

*IP哈希*

此方法仅适用于HTTP。 IP哈希使用客户端IP地址作为哈希。 与在通用散列中使用远程变量略有不同，此算法使用IPv4地址的前三个八位字节或整个IPv6地址。 只要该服务器可用，此方法就可确保客户端代理到同一个上游服务器，这在会话状态受到关注且不由应用程序的共享内存处理时非常有用。 在分发散列时，此方法还可以加入权重参数。 指令名称为ip_hash。
